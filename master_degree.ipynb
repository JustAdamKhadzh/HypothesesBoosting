{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions as utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor, Executor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, filename):\n",
    "    print(f'reading file = {os.path.join(path, filename)}')\n",
    "    data = pd.read_csv(os.path.join(path, filename))\n",
    "    data = data.rename(columns={'Unnamed: 0':'Id'})\n",
    "    print(f'data shape = {data.shape}')\n",
    "    types_info = pd.DataFrame(data.dtypes.value_counts(), columns=['columns_count'])\n",
    "    print('types info about df columns: ')\n",
    "    print(types_info)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls -la -h Datasets/GiveMeSomeCredit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file = Datasets/GiveMeSomeCredit/cs-training.csv\n",
      "data shape = (150000, 12)\n",
      "types info about df columns: \n",
      "         columns_count\n",
      "int64                8\n",
      "float64              4\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(path='Datasets/GiveMeSomeCredit/', filename='cs-training.csv')\n",
    "# test_data = read_data(path='Datasets/GiveMeSomeCredit/', filename='cs-test.csv')\n",
    "# descript = pd.read_excel(\"Datasets/GiveMeSomeCredit/Data Dictionary.xls\")\n",
    "# sample_data = pd.read_csv(\"Datasets/GiveMeSomeCredit/sampleEntry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(0, inplace=True)\n",
    "# test_data.fillna(0, inplace=True)\n",
    "\n",
    "#ставим колонку Id как индекс клиента\n",
    "train_data.set_index('Id', inplace=True)\n",
    "# test_data.set_index('Id', inplace=True)\n",
    "\n",
    "#сохраняем метку класса\n",
    "train_label = train_data['SeriousDlqin2yrs'].copy()\n",
    "train_data.drop('SeriousDlqin2yrs', axis=1, inplace=True)\n",
    "#удаляем колонку класса из тестовых данных, так как она не несет никакой информации\n",
    "# test_data.drop('SeriousDlqin2yrs', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['NumberOfDependents'] = train_data.NumberOfDependents.astype('int')\n",
    "train_data['MonthlyIncome'] = train_data.MonthlyIncome.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape#, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = train_data.select_dtypes('float').columns\n",
    "train_data.loc[:, float_cols] = train_data.loc[:, float_cols].round(2)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_cols = test_data.select_dtypes('float').columns\n",
    "# test_data.loc[:, float_cols] = test_data.loc[:, float_cols].round(2)\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train = utils.transform_to_description(train_data)\n",
    "# transformed_test = transform_to_description(test_data)\n",
    "# transformed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train.shape#, transformed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(transformed_train, train_label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX, testX, valY, testY = train_test_split(testX, testY, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 10) (30000, 10) (30000, 10)\n",
      "(90000,) (30000,) (30000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, valX.shape, testX.shape)\n",
    "print(trainY.shape, valY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм из работы Алексея(QBCA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "sample_ratio = 0.01\n",
    "num_iters = 100\n",
    "# N_neg = train_label.value_counts().reset_index().iloc[0, 1]\n",
    "# N_pos = train_label.value_counts().reset_index().iloc[1, 1]\n",
    "# N_neg, N_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**не обновляем индекс так как индекс - это id клиента, имеет значимую информацию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84021, 10), (5979, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pos = transformed_train.loc[train_label[train_label == 1].index]\n",
    "# train_neg = transformed_train.loc[train_label[train_label == 0].index]\n",
    "train_pos = trainX.loc[trainY[trainY == 1].index]\n",
    "train_neg = trainX.loc[trainY[trainY == 0].index]\n",
    "\n",
    "train_neg.shape, train_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Берем выборку заемов, для начального тестирования работоспособности**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 10), (2000, 10))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos = train_pos.sample(n=2000, random_state=123, replace=False)\n",
    "train_neg = train_neg.sample(n=2000, random_state=123, replace=False)\n",
    "train_pos.shape, train_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74880</th>\n",
       "      <td>(0.54, 0.54)</td>\n",
       "      <td>(46, 46)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.87, 0.87)</td>\n",
       "      <td>(2583, 2583)</td>\n",
       "      <td>(9, 9)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(2, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RevolvingUtilizationOfUnsecuredLines       age  \\\n",
       "Id                                                     \n",
       "74880                         (0.54, 0.54)  (46, 46)   \n",
       "\n",
       "      NumberOfTime30-59DaysPastDueNotWorse     DebtRatio MonthlyIncome  \\\n",
       "Id                                                                       \n",
       "74880                               (0, 0)  (0.87, 0.87)  (2583, 2583)   \n",
       "\n",
       "      NumberOfOpenCreditLinesAndLoans NumberOfTimes90DaysLate  \\\n",
       "Id                                                              \n",
       "74880                          (9, 9)                  (0, 0)   \n",
       "\n",
       "      NumberRealEstateLoansOrLines NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "Id                                                                        \n",
       "74880                       (1, 1)                               (0, 0)   \n",
       "\n",
       "      NumberOfDependents  \n",
       "Id                        \n",
       "74880             (2, 2)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = valX.sample(1)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining step\n",
    "\n",
    "\n",
    "    для положительного класса нас интересуют объекты отрицательного класса, \n",
    "    а для отрицательного - положительные\n",
    "    Уже после определения объектов из другого класса, попадающие в признаковое представление семпла данных, будет приниматься решение\n",
    "     о включение этого признакого представление в список гипотез представления(областей или интервальных представлений)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно посмотреть:\n",
    "\n",
    "    1. Сравнение количества генерируемых гипотез в зависимости от критерия и области генерации выборки.\n",
    "    (Возможно изобразить всего 4 варианта: старый подход - локальная или случайная выборка, новый подход - \n",
    "    локальная или случайная выборка)\n",
    "    \n",
    "    2. Сравнение генерируемых гипотез для старого и нового критерия в зависимости от ширины локальной области генерации\n",
    "    (Возможно есть какая то оптимальная ширина окна)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do-list:\n",
    "1. **классификации при разном включении признаков из исходного множества**\n",
    "\n",
    "2. **Подумать о том, каким образом генерить гипотезы. То есть выбирать не случайно выборку из множества объектов,\n",
    "    а какую-то локальную область. (Делать будем через расширение области объекта; более того, будем искать \n",
    "    оптимальное значение расширения локальной области) done !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hypothesis(iteration: int, obj: pd.Series, object_area: pd.Series, train_data: pd.DataFrame, \n",
    "                        other_data: pd.DataFrame, sample_size: int, hypothesis_criterion: str,\n",
    "                        sample_type:str, verbose: bool, alpha: float):\n",
    "        \n",
    "        print(f'iteration: {iteration}')\n",
    "        \n",
    "#         if sample_type == 'local' and object_area is None:\n",
    "#             print(f'Cannot generate sample from local area. Got None as local object area param!')\n",
    "#             return None\n",
    "    \n",
    "#         if sample_type == 'random' and object_area is not None:\n",
    "#             print(f'got misleading params values. Got sample_type = None and local object area is not None')\n",
    "#             return None\n",
    "\n",
    "        #generating random sample using sample strategy = {sample_type}\n",
    "        sample = utils.generate_random_sample(train_data=train_data, sample_size=sample_size, d=object_area) \n",
    "        sample.append(obj)\n",
    "        \n",
    "        d = utils.get_similarity_sample_repr(sample)\n",
    "        if verbose:\n",
    "            print('got feature represantation for sample')\n",
    "        \n",
    "        d_other_objects = utils.is_included_in_repr(d, train_data=other_data)\n",
    "        if d_other_objects is not None:\n",
    "            print(f'got {len(d_other_objects)} d_other_objects')\n",
    "            print(f'thresh for hypothesis = {int(other_data.shape[0] * alpha)}')\n",
    "        \n",
    "#         if verbose:\n",
    "#             print('got objects that is included in sample represantation')\n",
    "        #!!!!!!!\n",
    "        # Тут момент такой, что вроде если d_other_objects тоже подходит, так как в этой области только объекты одного класса\n",
    "        # а объектов другого просто нет\n",
    "        if d_other_objects is None:\n",
    "            print('!'*20)\n",
    "            print('did not find any hypothesis on this iteration')\n",
    "            return d # эта гипотеза подходит, никого нет из другого класса, можно больше ничего не проверять\n",
    "        \n",
    "        \n",
    "        result_hypothesis = utils.check_criterion(d=d, train_data=train_data, \n",
    "                                                  hypothesis_criterion=hypothesis_criterion, \n",
    "                                                  d_other_objects=d_other_objects,\n",
    "                                                  other_data=other_data, alpha=alpha\n",
    "                                                 )\n",
    "\n",
    "        return result_hypothesis\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "def mining_step(test_obj: pd.Series,train_pos: pd.DataFrame, train_neg: pd.DataFrame, num_iters: int, \n",
    "                sample_ratio: float, alpha: float, hypothesis_criterion: str, sample_type: str,\n",
    "                mining_type: str = 'pos', verbose : bool = False, n_jobs : int = 4):\n",
    "    \"\"\"\n",
    "    hypothesis_criterion: 'contr_class', если используем базовый критерий, \n",
    "                                когда смотрится пересечение с противоположным классом(старый критерий отбора гипотез)\n",
    "                           'both_classes', когда интересует пересечение по обоим классам(новый критерий отбора гипотез)\n",
    "                           \n",
    "    sample_type: 'random', если берем произвольную выборку интервальных представлений\n",
    "                 'local', если берем произвольную выборку из локальной области\n",
    "    \n",
    "    returns list of hypothesises\n",
    "    \"\"\"\n",
    "    \n",
    "    if sample_type == 'local':\n",
    "        #sampling\n",
    "        print(f'start searching optimal local area')\n",
    "        object_area = utils.find_opt_local_area(obj=test_obj,\n",
    "                                                train_data=train_data,\n",
    "                                                frac=0.15,\n",
    "                                                num_iters=30\n",
    "                                               )\n",
    "    else:\n",
    "        print(f'using random sample from train data')\n",
    "        object_area = None\n",
    "    \n",
    "    train_data = train_pos if mining_type == 'pos' else train_neg\n",
    "    other_data = train_neg if mining_type == 'pos' else train_pos\n",
    "    sample_size = int(train_data.shape[0] * sample_ratio)\n",
    "    print('start generating hypothesises')\n",
    "    \n",
    "    mining = partial(generate_hypothesis, \n",
    "                     obj=test_obj, \n",
    "                     object_area=object_area,\n",
    "                     train_data=train_data, \n",
    "                     other_data=other_data, \n",
    "                     sample_size=sample_size, \n",
    "                     hypothesis_criterion=hypothesis_criterion,\n",
    "                     sample_type=sample_type,\n",
    "                     verbose=verbose,\n",
    "                     alpha=alpha\n",
    "                    )\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        hypothesises = executor.map(mining, range(num_iters))\n",
    "\n",
    "    hypothesises = [res for res in hypothesises if res is not None]\n",
    "    print(f'All hypothesises are generated!')\n",
    "    return hypothesises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     area = utils.find_opt_local_area(obj=obj, train_data=train_pos, num_iters=100)\n",
    "#     if area is not None:\n",
    "#         print('we found area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_local_sample(d=area, train_data=train_pos, sample_size=int(sample_ratio * train_pos.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_neg_objs = is_included_in_repr(d=area, train_data=train_neg)\n",
    "# local_objs = is_included_in_repr(d=area, train_data=train_pos)\n",
    "# len(local_objs), train_pos.shape, len(local_neg_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     sample = generate_local_sample(obj, train_data=train_pos, sample_size=3, num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     print(type(obj))\n",
    "# #     generate_local_sample(obj=obj, train_data=train_pos, sample_size=3)\n",
    "#     generated = generate_local_area(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_local_obj = transformed_train.sample(1)\n",
    "# test_local_obj\n",
    "\n",
    "# generated_obj = generate_local_area(test_local_obj)\n",
    "# generated_obj\n",
    "\n",
    "# generate_local_area(generated_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "sample_ratio = 0.001\n",
    "num_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos.shape[0] * sample_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_hyps = []\n",
    "neg_hyps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация гипотез для полож класса занимает 10 мин (с 4 процессами) c 3000 iterations**\n",
    "**c 1000 iterations - 2 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "start mining from neg objects\n",
      "using random sample from train data\n",
      "start generating hypothesises\n",
      "iteration: 0\n",
      "iteration: 1\n",
      "iteration: 2\n",
      "iteration: 3\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 4\n",
      "got 3 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 5\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 6\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 7\n",
      "got 2 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 8\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 10\n",
      "iteration: 9\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 11\n",
      "got 27 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 12\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 13\n",
      "iteration: 14\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 15\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 16\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "got 2 d_other_objects\n",
      "did not find any hypothesis on this iteration\n",
      "thresh for hypothesis = 10\n",
      "iteration: 17\n",
      "iteration: 18\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 19\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 20\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 21\n",
      "got 3 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 22\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 23\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 24\n",
      "got 16 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "got 1 d_other_objects\n",
      "iteration: 25\n",
      "thresh for hypothesis = 10\n",
      "iteration: 26\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 27\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 28\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 29\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 30\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 31\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 32\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 33\n",
      "got 3 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 34\n",
      "got 2 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 35\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 36\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 37\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 38\n",
      "got 25 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 39\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 40\n",
      "got 4 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 41\n",
      "got 5 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 42\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 43\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 44\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 45\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 46\n",
      "got 4 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 47\n",
      "got 46 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 48\n",
      "got 2 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 49\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 50\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 51\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 52\n",
      "iteration: 53\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 54\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 55\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 56\n",
      "iteration: 57\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 58\n",
      "got 25 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 59\n",
      "got 2 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 60\n",
      "iteration: 61\n",
      "got 4 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 62\n",
      "got 8 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 63\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "got 1 d_other_objects\n",
      "did not find any hypothesis on this iteration\n",
      "thresh for hypothesis = 10\n",
      "iteration: 64\n",
      "iteration: 65\n",
      "got 5 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 66\n",
      "got 4 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 67\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 68\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 69\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 70\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 71\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 72\n",
      "got 2 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 73\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 74\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 75\n",
      "got 4 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 76\n",
      "got 5 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 77\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 78\n",
      "iteration: 79\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 80\n",
      "got 38 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 81\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 82\n",
      "got 8 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 83\n",
      "got 3 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 84\n",
      "iteration: 85\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 86\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 87\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 88\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 89\n",
      "got 9 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 90\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 91\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 92\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 93\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 95\n",
      "iteration: 94\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 96\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "iteration: 97\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "got 1 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "iteration: 98\n",
      "iteration: 99\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "got 18 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "did not find any hypothesis on this iteration\n",
      "got 3 d_other_objects\n",
      "thresh for hypothesis = 10\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "did not find any hypothesis on this iteration\n",
      "All hypothesises are generated!\n",
      "CPU times: user 1.91 s, sys: 324 ms, total: 2.24 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, obj in test_sample.iterrows():\n",
    "    print(type(obj))\n",
    "#     print(f'start mining from pos objects')\n",
    "#     pos_hyps = mining_step(test_obj=obj, train_pos=train_pos, train_neg=train_neg, \n",
    "#                            num_iters=num_iters,sample_ratio=sample_ratio, alpha = alpha,\n",
    "#                            hypothesis_criterion='contr_class',\n",
    "#                            sample_type='random',\n",
    "#                            mining_type='pos',\n",
    "#                            verbose=False, n_jobs=4\n",
    "#                           )\n",
    "    \n",
    "    print(f'start mining from neg objects')\n",
    "    neg_hyps = mining_step(test_obj=obj, train_pos=train_pos, train_neg=train_neg,\n",
    "                           num_iters=num_iters, sample_ratio=sample_ratio, alpha = alpha, \n",
    "                           hypothesis_criterion='contr_class',mining_type='neg', \n",
    "                           sample_type='random',\n",
    "                           verbose=False, n_jobs=4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_hyps = pd.DataFrame(neg_hyps)\n",
    "# neg_hyps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_hyps.to_csv('hypothesises/test_neg_hyps.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_hyps = pd.DataFrame(pos_hyps)\n",
    "# pos_hyps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_hyps.to_csv(\"hypothesises/test_pos_hyps.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135557 <class 'pandas.core.series.Series'>\n",
      "27835 <class 'pandas.core.series.Series'>\n",
      "132837 <class 'pandas.core.series.Series'>\n",
      "21603 <class 'pandas.core.series.Series'>\n",
      "53242 <class 'pandas.core.series.Series'>\n",
      "124184 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, obj in trainX.iterrows():\n",
    "    count += 1\n",
    "    print(i, type(obj))\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesises_to_feat_matrix(pos_hyps: pd.DataFrame, neg_hyps: pd.DataFrame, trainX: pd.DataFrame):\n",
    "    pos_features = [f'pos_feat_{feat_num}' for feat_num in pos_hyps.index]\n",
    "#     neg_features = [f'neg_feat_{feat_num}' for feat_num in neg_hyps.index]\n",
    "    \n",
    "    result = pd.DataFrame(index=trainX.index, columns=pos_features)# + neg_features)\n",
    "    \n",
    "    for i, obj in trainX.iterrows():\n",
    "        for pi, pos_hyp in pos_hyps.iterrows():\n",
    "            feat_repr = utils.similarity(obj, pos_hyp)\n",
    "            is_included = pos_hyp.equals(feat_repr)\n",
    "            if is_included:\n",
    "                result.loc[i, f'pos_feat_{pi}'] = 1\n",
    "            else:\n",
    "                result.loc[i, f'pos_feat_{pi}'] = 0\n",
    "                \n",
    "#         for pi, neg_hyp in neg_hyps.iterrows():\n",
    "#             feat_repr = utils.similarity(obj, neg_hyp)\n",
    "#             is_included = neg_hyp.equals(feat_repr)\n",
    "#             if is_included:\n",
    "#                 result.loc[i, f'neg_feat_{pi}'] = 1\n",
    "#             else:\n",
    "#                 result.loc[i, f'neg_feat_{pi}'] = 0\n",
    "    \n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Данный вариант не прокатит, слишком долго\n",
    "### Нужно придумать другой вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-34355f1b1d2a>\u001b[0m in \u001b[0;36mhypothesises_to_feat_matrix\u001b[0;34m(pos_hyps, neg_hyps, trainX)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'pos_feat_{pi}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'pos_feat_{pi}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         for pi, neg_hyp in neg_hyps.iterrows():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             self.obj._data = self.obj._data.setitem(indexer=indexer,\n\u001b[0;32m--> 651\u001b[0;31m                                                     value=value)\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3693\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'setitem'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3581\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, indexer, value, mgr)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# coerce and try to infer the dtypes of the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_try_coerce_and_cast_result\u001b[0;34m(self, result, dtype)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_coerce_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_try_cast_result\u001b[0;34m(self, result, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;31m# may need to change the dtype here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_downcast_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_coerce_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_downcast_to_dtype\u001b[0;34m(result, dtype)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0minferred_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bool'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = hypothesises_to_feat_matrix(pos_hyps=pos_hyps, neg_hyps=neg_hyps, trainX=trainX.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.Series({'feat1':(1,1), 'feat2':(0, 1.4), 'feat3':(3, 4)})\n",
    "# b = pd.Series({'feat1':(1,2), 'feat2':(1, 1.4), 'feat3':(7, 7)})\n",
    "# c = pd.Series({'feat1':(1,1), 'feat2':(0.8, 1.6), 'feat3':(3, 4)})\n",
    "# d = pd.Series({'feat1':(2,3), 'feat2':(0, 1.4), 'feat3':(4, 6)})\n",
    "\n",
    "\n",
    "# print(a.equals(b))\n",
    "# print(a == b)\n",
    "\n",
    "# test1 = pd.Series({'feat1':(1,3), 'feat2':(1, 3.4), 'feat3':(1, 1.9)})\n",
    "# test2 = pd.Series({'feat1':(2,2.2), 'feat2':(2, 2.4), 'feat3':(3, 3.9)})\n",
    "# test3 = pd.Series({'feat1':(3,3), 'feat2':(4, 4.4), 'feat3':(4, 4.9)})\n",
    "\n",
    "g1 = pd.Series({'feat1':(1,1), 'feat2':(1.5, 1.5)})\n",
    "g2 = pd.DataFrame({'feat1':(-1,-1), 'feat2':(0, 0)})\n",
    "g3 = pd.Series({'feat1':(0.5,0.5), 'feat2':(1, 1)})\n",
    "\n",
    "test1 = pd.Series({'feat1':(0.1, 1), 'feat2':(-0.5, 0)})\n",
    "test2 = pd.DataFrame({'feat1':(-0.1, 1), 'feat2':(0.5, 0.8)})\n",
    "tst = pd.Series({'feat1':(-1, 1), 'feat2':(0, 1.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,obj in sample.iterrows():\n",
    "#     print(similarity(pd.DataFrame(d).T, obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = pd.DataFrame([g1, g2, g3, test1, test2])\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat1        (1, 1)\n",
       "feat2    (1.5, 1.5)\n",
       "dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d), type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_included_in_repr(d, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая функция провекри np.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat(times, data):\n",
    "    print(f\"times = {times}\")\n",
    "    sample = np.random.RandomState().choice(data, replace=False, size=10)\n",
    "    print(f\"sample = {sample}\")\n",
    "    sample_sum = np.sum(sample)\n",
    "    print(f\"sample sum = {sample_sum}\")\n",
    "    return sample_sum\n",
    "\n",
    "def run_computing(n_jobs=2):\n",
    "    data = list(range(100))\n",
    "    \n",
    "    compute_func = partial(compute_stat, data=data)\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        results = executor.map(compute_func, list(range(26)))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = run_computing(n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
