{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions as func\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor, Executor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, filename):\n",
    "    print(f'reading file = {os.path.join(path, filename)}')\n",
    "    data = pd.read_csv(os.path.join(path, filename))\n",
    "    data = data.rename(columns={'Unnamed: 0':'Id'})\n",
    "    print(f'data shape = {data.shape}')\n",
    "    types_info = pd.DataFrame(data.dtypes.value_counts(), columns=['columns_count'])\n",
    "    print('types info about df columns: ')\n",
    "    print(types_info)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28272\r\n",
      "drwx------@ 6 adam  staff   192B Dec 23 21:30 \u001b[34m.\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  8 adam  staff   256B Dec 23 21:36 \u001b[34m..\u001b[m\u001b[m/\r\n",
      "-rwxr-xr-x@ 1 adam  staff    15K Dec 11  2019 \u001b[31mData Dictionary.xls\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@ 1 adam  staff   4.8M Dec 11  2019 \u001b[31mcs-test.csv\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@ 1 adam  staff   7.2M Dec 11  2019 \u001b[31mcs-training.csv\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@ 1 adam  staff   1.8M Dec 11  2019 \u001b[31msampleEntry.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls -la -h Datasets/GiveMeSomeCredit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file = Datasets/GiveMeSomeCredit/cs-training.csv\n",
      "data shape = (150000, 12)\n",
      "types info about df columns: \n",
      "         columns_count\n",
      "int64                8\n",
      "float64              4\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(path='Datasets/GiveMeSomeCredit/', filename='cs-training.csv')\n",
    "# test_data = read_data(path='Datasets/GiveMeSomeCredit/', filename='cs-test.csv')\n",
    "# descript = pd.read_excel(\"Datasets/GiveMeSomeCredit/Data Dictionary.xls\")\n",
    "# sample_data = pd.read_csv(\"Datasets/GiveMeSomeCredit/sampleEntry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_description(data: pd.DataFrame):\n",
    "    transformed_data = pd.DataFrame(columns=data.columns)\n",
    "    \n",
    "    for col in data:\n",
    "        transformed_data[col] = data[col].apply(lambda x: (x, x))\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(0, inplace=True)\n",
    "# test_data.fillna(0, inplace=True)\n",
    "\n",
    "#ставим колонку Id как индекс клиента\n",
    "train_data.set_index('Id', inplace=True)\n",
    "# test_data.set_index('Id', inplace=True)\n",
    "\n",
    "#сохраняем метку класса\n",
    "train_label = train_data['SeriousDlqin2yrs'].copy()\n",
    "train_data.drop('SeriousDlqin2yrs', axis=1, inplace=True)\n",
    "#удаляем колонку класса из тестовых данных, так как она не несет никакой информации\n",
    "# test_data.drop('SeriousDlqin2yrs', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['NumberOfDependents'] = train_data.NumberOfDependents.astype('int')\n",
    "train_data['MonthlyIncome'] = train_data.MonthlyIncome.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape#, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = train_data.select_dtypes('float').columns\n",
    "train_data.loc[:, float_cols] = train_data.loc[:, float_cols].round(2)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_cols = test_data.select_dtypes('float').columns\n",
    "# test_data.loc[:, float_cols] = test_data.loc[:, float_cols].round(2)\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train = transform_to_description(train_data)\n",
    "# transformed_test = transform_to_description(test_data)\n",
    "# transformed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train.shape#, transformed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(transformed_train, train_label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX, testX, valY, testY = train_test_split(testX, testY, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 10) (30000, 10) (30000, 10)\n",
      "(90000,) (30000,) (30000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, valX.shape, testX.shape)\n",
    "print(trainY.shape, valY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(vect1: pd.Series, vect2:pd.Series):\n",
    "    \n",
    "    \"\"\"\n",
    "    previous version:\n",
    "     vect1 = transformed_train.iloc[0]\n",
    "     vect2 = transformed_train.iloc[2]\n",
    "     func = (lambda x,y: (min(x[0], y[0]), max(x[1], y[1])))\n",
    "     pd.Series(map(func, vect1, vect2), index=train_data.columns)\n",
    "    \n",
    "     for col in cols:\n",
    "     vect_min = min(vect1.loc[col][0], vect2.loc[col][0])\n",
    "     vect_max = max(vect1.loc[col][1], vect2.loc[col][1])\n",
    "     vect[col] = (vect_min, vect_max)\n",
    "    \"\"\"\n",
    "    \n",
    "    func = lambda x, y: (min(x[0], y[0]), max(x[1], y[1]))\n",
    "    vect = pd.Series(map(func, vect1, vect2), index=vect1.index)\n",
    "    return vect\n",
    "\n",
    "def inclusion(obj, patterns):\n",
    "    \"\"\"\n",
    "    check where an obj is inluded in list of patterns\n",
    "    is_include = any([all(obj == elem) for elem in patterns])\n",
    "    \"\"\"     \n",
    "    is_include = any([obj.equals(elem) for elem in patterns])\n",
    "    return  is_include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм из работы Алексея(QBCA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.003\n",
    "sample_ratio = 0.003\n",
    "num_iters = 100\n",
    "# N_neg = train_label.value_counts().reset_index().iloc[0, 1]\n",
    "# N_pos = train_label.value_counts().reset_index().iloc[1, 1]\n",
    "# N_neg, N_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**не обновляем индекс так как индекс - это id клиента, имеет значимую информацию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83974, 10), (6026, 10))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pos = transformed_train.loc[train_label[train_label == 1].index]\n",
    "# train_neg = transformed_train.loc[train_label[train_label == 0].index]\n",
    "train_pos = trainX.loc[trainY[trainY == 1].index]\n",
    "train_neg = trainX.loc[trainY[trainY == 0].index]\n",
    "\n",
    "train_neg.shape, train_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Берем выборку заемов, для начального тестирования работоспособности**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000, 10))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos = train_pos.sample(n=1000, random_state=123, replace=False)\n",
    "train_neg = train_neg.sample(n=1000, random_state=123, replace=False)\n",
    "train_pos.shape, train_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108667</th>\n",
       "      <td>(0.3, 0.3)</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.34, 0.34)</td>\n",
       "      <td>(5600, 5600)</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RevolvingUtilizationOfUnsecuredLines       age  \\\n",
       "Id                                                      \n",
       "108667                           (0.3, 0.3)  (32, 32)   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse     DebtRatio MonthlyIncome  \\\n",
       "Id                                                                        \n",
       "108667                               (0, 0)  (0.34, 0.34)  (5600, 5600)   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans NumberOfTimes90DaysLate  \\\n",
       "Id                                                               \n",
       "108667                          (8, 8)                  (0, 0)   \n",
       "\n",
       "       NumberRealEstateLoansOrLines NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "Id                                                                         \n",
       "108667                       (1, 1)                               (0, 0)   \n",
       "\n",
       "       NumberOfDependents  \n",
       "Id                         \n",
       "108667             (0, 0)  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = valX.sample(1)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_similarity_sample_repr and is_included_in_repr работают вроде правильно**\n",
    "\n",
    "По крайней мере на тестовых объектах показали правильные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_sample_repr(sample: pd.DataFrame):\n",
    "    \n",
    "    \"\"\"\n",
    "    get sample of feature represantations from pos or neg class dataset\n",
    "    returns feature represantation for sample by similarity operation\n",
    "    \"\"\"\n",
    "    pattern = None\n",
    "    for i, obj in sample.iterrows():\n",
    "        if pattern is None:\n",
    "            pattern = obj\n",
    "        else:\n",
    "            pattern = similarity(pattern, obj)\n",
    "    return pattern\n",
    "    \n",
    "#операция нахождения объектов по признаковому представлению\n",
    "def is_included_in_repr(d: pd.Series, train_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    returns objects from train dataset(from train pos and neg data) that is included in d representation\n",
    "    \"\"\"\n",
    "    \n",
    "    d_list = []\n",
    "    \n",
    "    for i, obj in train_data.iterrows():\n",
    "        feature_repr = similarity(obj, d)\n",
    "        is_included = d.equals(feature_repr)\n",
    "        if is_included:\n",
    "            d_list.append(obj)\n",
    "    d_list = pd.DataFrame(d_list) if len(d_list) > 0 else None\n",
    "    return d_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining step\n",
    "\n",
    "\n",
    "    для положительного класса нас интересуют объекты отрицательного класса, \n",
    "    а для отрицательного - положительные\n",
    "    Уже после определения объектов из другого класса, попадающие в признаковое представление семпла данных, будет приниматься решение\n",
    "     о включение этого признакого представление в список гипотез представления(областей или интервальных представлений)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно посмотреть:\n",
    "\n",
    "    1. Сравнение количества генерируемых гипотез в зависимости от критерия и области генерации выборки.\n",
    "    (Возможно изобразить всего 4 варианта: старый подход - локальная или случайная выборка, новый подход - \n",
    "    локальная или случайная выборка)\n",
    "    \n",
    "    2. Сравнение генерируемых гипотез для старого и нового критерия в зависимости от ширины локальной области генерации\n",
    "    (Возможно есть какая то оптимальная ширина окна)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do-list:\n",
    "1. **классификации при разном включении признаков из исходного множества**\n",
    "\n",
    "2. **Подумать о том, каким образом генерить гипотезы. То есть выбирать не случайно выборку из множества объектов,\n",
    "    а какую-то локальную область. (Делать будем через расширение области объекта; более того, будем искать \n",
    "    оптимальное значение расширения локальной области)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hypothesis(iteration: int,\n",
    "                        obj: pd.Series, \n",
    "                        train_data: pd.DataFrame, \n",
    "                        other_data: pd.DataFrame, \n",
    "                        sample_size: int, \n",
    "                        hypothesis_criterion: str,\n",
    "                        sample_type:str,\n",
    "                        verbose: bool,\n",
    "                        other_data_size: int, \n",
    "                        alpha: float):\n",
    "        \n",
    "        print(f'iteration: {iteration}')\n",
    "        # Генерация семпла данных, по которым будут вычисляться гипотезы\n",
    "        # Параметр sample_type определяет область, из которой будут генерироваться гипотезы\n",
    "        if sample_type == 'random':\n",
    "            inds = np.random.RandomState().choice(train_data.index, replace=False, size=sample_size)\n",
    "            sample = train_data.loc[inds, :].copy()\n",
    "            sample = sample.append(obj)\n",
    "        elif sample_type == 'local':\n",
    "            #генерация семпла данных из локальной области\n",
    "            sample = generate_local_sample(obj=obj, train_data=train_data, sample_size=sample_size)\n",
    "            sample.append(obj)\n",
    "        else:\n",
    "            print('Не задали тип семплирования')\n",
    "            return None\n",
    "        \n",
    "        d = get_similarity_sample_repr(sample)\n",
    "        if verbose:\n",
    "            print('got feature represantation for sample')\n",
    "        \n",
    "        d_other_objects = is_included_in_repr(d, train_data=other_data)\n",
    "        #print(f'got {len(d_other_objects)} d_other_objects')\n",
    "        #print(f'thresh for hypothesis = {int(other_data_size * alpha)}')\n",
    "        \n",
    "#         if verbose:\n",
    "#             print('got objects that is included in sample represantation')\n",
    "        #!!!!!!!\n",
    "        # Тут момент такой, что вроде если d_other_objects тоже подходит, так как в этой области только объекты одного класса\n",
    "        # а объектов другого просто нет\n",
    "        if d_other_objects is None:\n",
    "            print('!'*20)\n",
    "            print('did not find any hypothesis on this iteration')\n",
    "            return d # эта гипотеза подходит, никого нет из другого класса, можно больше ничего не проверять\n",
    "        \n",
    "        ###проверка критерия\n",
    "        if hypothesis_criterion == 'contr_class':\n",
    "            if d_other_objects.shape[0] <= int(other_data_size * alpha):\n",
    "                return d\n",
    "        elif hypothesis_criterion == 'both_classes':\n",
    "            #дополнительно смотрим какие объекты target(рассматриваемого на этой итерации) класса попадают в паттерн d\n",
    "            d_target_objects = is_included_in_repr(d, train_data=train_data)\n",
    "            if d_other_objects.shape[0] <= int(d_target_objects.shape[0] * alpha):\n",
    "                return d\n",
    "        else:\n",
    "            print('did not get any hyp on this iteration')\n",
    "            return None\n",
    "\n",
    "def mining_step(test_obj: pd.Series, \n",
    "                train_pos: pd.DataFrame, \n",
    "                train_neg: pd.DataFrame,\n",
    "                num_iters: int, \n",
    "                sample_ratio: float, \n",
    "                alpha: float, \n",
    "                hypothesis_criterion: str, \n",
    "                sample_type: str,\n",
    "                mining_type: str = 'pos', \n",
    "                verbose : bool = False, \n",
    "                n_jobs : int = 4):\n",
    "    \"\"\"\n",
    "    hypothesis_criterion: 'contr_class', если используем базовый критерий, \n",
    "                                когда смотрится пересечение с противоположным классом(старый критерий отбора гипотез)\n",
    "                           'both_classes', когда интересует пересечение по обоим классам(новый критерий отбора гипотез)\n",
    "    sample_type: 'random', если берем произвольную выборку интервальных представлений\n",
    "                 'local', если берем произвольную выборку из локальной области\n",
    "    \n",
    "    returns list of hypothesises\n",
    "    \"\"\"\n",
    "    \n",
    "#     Здесь нужно поставить расчет локальной области объекта, иначе\n",
    "# для одного объекта в каждом потоке будет пересчитываться область\n",
    "\n",
    "#Таким образом, здесь мы расчитаем область для объекта, и далее передадим в функцию, где будет происходить случайное семплирование\n",
    "    \n",
    "    train_data = train_pos if mining_type == 'pos' else train_neg\n",
    "    other_data = train_neg if mining_type == 'pos' else train_pos\n",
    "    other_data_size = train_neg.shape[0] if mining_type == 'pos' else train_pos.shape[0]\n",
    "    \n",
    "    sample_size = int(train_data.shape[0] * sample_ratio)\n",
    "    print('start generating hypothesises')\n",
    "    \n",
    "    mining = partial(generate_hypothesis, \n",
    "                     obj=test_obj, \n",
    "                     train_data=train_data, \n",
    "                     other_data=other_data, \n",
    "                     sample_size=sample_size, \n",
    "                     hypothesis_criterion=hypothesis_criterion,\n",
    "                     sample_type=sample_type,\n",
    "                     verbose=verbose, \n",
    "                     other_data_size=other_data_size,\n",
    "                     alpha=alpha\n",
    "                    )\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        hypothesises = executor.map(mining, range(num_iters))\n",
    "\n",
    "    hypothesises = [res for res in hypothesises if res is not None]\n",
    "    return hypothesises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RevolvingUtilizationOfUnsecuredLines      (0.3, 0.3)\n",
       "age                                         (32, 32)\n",
       "NumberOfTime30-59DaysPastDueNotWorse          (0, 0)\n",
       "DebtRatio                               (0.34, 0.34)\n",
       "MonthlyIncome                           (5600, 5600)\n",
       "NumberOfOpenCreditLinesAndLoans               (8, 8)\n",
       "NumberOfTimes90DaysLate                       (0, 0)\n",
       "NumberRealEstateLoansOrLines                  (1, 1)\n",
       "NumberOfTime60-89DaysPastDueNotWorse          (0, 0)\n",
       "NumberOfDependents                            (0, 0)\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = test_sample.reset_index(drop=True).T\n",
    "pd.Series(t.to_dict()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#старая версия, уже не нужна в принципе\n",
    "def generate_local_area_old(obj: pd.DataFrame):\n",
    "    eps = 0\n",
    "    index = obj.index.values[0]\n",
    "    local_obj = pd.DataFrame(index=[index], columns=obj.columns)\n",
    "    for key in obj.columns:\n",
    "        left_val, right_val = obj[key].iloc[0]\n",
    "        if isinstance(left_val, int):\n",
    "            eps = 1 if abs(left_val) // 100 == 0 else 100\n",
    "        elif isinstance(left_val, float):\n",
    "            eps = 0.01\n",
    "        left_val, right_val = left_val - eps, right_val + eps \n",
    "        local_obj.loc[index, key] = (left_val, right_val)\n",
    "    return local_obj\n",
    "#данную функцию переписали, чтобы соответствовала общей логике подсчета\n",
    "def generate_local_area(obj: pd.Series):\n",
    "    eps = 0\n",
    "    index = obj.name\n",
    "    local_obj = {}\n",
    "    for feat, val in obj.items():\n",
    "        left_val, right_val = val\n",
    "        if isinstance(left_val, int):\n",
    "            eps = 1 if abs(left_val) // 100 == 0 else 100\n",
    "        elif isinstance(left_val, float):\n",
    "            eps = 0.01 if abs(left_val) // 10 == 0 else 100\n",
    "        left_val, right_val = left_val - eps, right_val + eps\n",
    "        local_obj[feat] = (left_val, right_val)\n",
    "    local_obj = pd.Series(local_obj)\n",
    "    local_obj.name = index\n",
    "    return local_obj\n",
    "\n",
    "#здесь высчитвается локальная область, которая передается функции генерации семпла\n",
    "def find_opt_local_area(obj: pd.Series, train_data: pd.DataFrame,\n",
    "                       frac: float = 0.15, num_iters=10):\n",
    "    #нужно запихнуть сюда код, который занимается именно поиском области,\n",
    "    #а в generate_local_sample оставить именно генерацию семпла по области\n",
    "    return pd.Series([])# на выходе имеенно вектор, содержащий область\n",
    "\n",
    "#здесь будет именно генерация семла в каждом потоке отдельно\n",
    "\n",
    "def generate_local_sample(d: pd.Series, \n",
    "                          train_data: pd.DataFrame, \n",
    "                          sample_size: int, \n",
    "                          frac: float = 0.15,\n",
    "                          num_iters=10):\n",
    "    \n",
    "    iters = num_iters\n",
    "    sample = None\n",
    "    d_local_area = obj\n",
    "    print(f'start generating local sample')\n",
    "#     Возможно нужно добавить условие на количество объектов в области но не больше какое то количество итераций\n",
    "    objects_count = 0\n",
    "    objs_count_thresh = int(train_data.shape[0] * frac)\n",
    "    while objects_count < objs_count_thresh and iters > 0:\n",
    "        print(f'itr: {iters}')\n",
    "        d_local_area = generate_local_area(d_local_area)\n",
    "        d_local_objects = is_included_in_repr(d=d_local_area, train_data=train_data)\n",
    "        if d_local_objects is not None:\n",
    "            objects_count = d_local_objects.shape[0]\n",
    "            print(f\"d_local_object = {len(d_local_objects)}\")\n",
    "            if objects_count > objs_count_thresh:\n",
    "                inds = np.random.RandomState().choice(d_local_objects.index, replace=False, size=sample_size)\n",
    "                sample = d_local_objects.loc[inds]\n",
    "                print(f'found sample')\n",
    "                break\n",
    "        iters -= 1\n",
    "    if sample is None:\n",
    "        print('Not enough iterations. You shoud use more iterations or choose another obj. Maybe it is outlier.')\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     sample = generate_local_sample(obj, train_data=train_pos, sample_size=3, num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     print(type(obj))\n",
    "# #     generate_local_sample(obj=obj, train_data=train_pos, sample_size=3)\n",
    "#     generated = generate_local_area(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_local_obj = transformed_train.sample(1)\n",
    "# test_local_obj\n",
    "\n",
    "# generated_obj = generate_local_area(test_local_obj)\n",
    "# generated_obj\n",
    "\n",
    "# generate_local_area(generated_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_hyps = []\n",
    "neg_hyps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация гипотез для полож класса занимает 10 мин (с 4 процессами) c 3000 iterations**\n",
    "**c 1000 iterations - 2 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for i, obj in test_sample.iterrows():\n",
    "#     print(type(obj))\n",
    "#     print(f'start mining from pos objects')\n",
    "#     pos_hyps = mining_step(test_obj=obj, train_pos=train_pos, train_neg=train_neg, \n",
    "#                            num_iters=num_iters,sample_ratio=sample_ratio, alpha = alpha,\n",
    "#                            hypothesis_criterion='contr_class',\n",
    "#                            sample_type='local',\n",
    "#                            mining_type='pos',\n",
    "#                            verbose=False, n_jobs=4\n",
    "#                           )\n",
    "    \n",
    "# #     print(f'start mining from neg objects')\n",
    "# #     neg_hyps = mining_step(test_obj=obj, train_pos=train_pos, train_neg=train_neg,\n",
    "# #                            num_iters=num_iters, sample_ratio=sample_ratio, alpha = alpha, \n",
    "# #                            hypothesis_criterion='contr_class',mining_type='neg', \n",
    "# #                            sample_type='',\n",
    "# #                            verbose=True, n_jobs=4\n",
    "# #                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.Series({'feat1':(1,1), 'feat2':(0, 1.4), 'feat3':(3, 4)})\n",
    "# b = pd.Series({'feat1':(1,2), 'feat2':(1, 1.4), 'feat3':(7, 7)})\n",
    "# c = pd.Series({'feat1':(1,1), 'feat2':(0.8, 1.6), 'feat3':(3, 4)})\n",
    "# d = pd.Series({'feat1':(2,3), 'feat2':(0, 1.4), 'feat3':(4, 6)})\n",
    "\n",
    "\n",
    "# print(a.equals(b))\n",
    "# print(a == b)\n",
    "\n",
    "# test1 = pd.Series({'feat1':(1,3), 'feat2':(1, 3.4), 'feat3':(1, 1.9)})\n",
    "# test2 = pd.Series({'feat1':(2,2.2), 'feat2':(2, 2.4), 'feat3':(3, 3.9)})\n",
    "# test3 = pd.Series({'feat1':(3,3), 'feat2':(4, 4.4), 'feat3':(4, 4.9)})\n",
    "\n",
    "g1 = pd.Series({'feat1':(1,1), 'feat2':(1.5, 1.5)})\n",
    "g2 = pd.DataFrame({'feat1':(-1,-1), 'feat2':(0, 0)})\n",
    "g3 = pd.Series({'feat1':(0.5,0.5), 'feat2':(1, 1)})\n",
    "\n",
    "test1 = pd.Series({'feat1':(0.1, 1), 'feat2':(-0.5, 0)})\n",
    "test2 = pd.DataFrame({'feat1':(-0.1, 1), 'feat2':(0.5, 0.8)})\n",
    "tst = pd.Series({'feat1':(-1, 1), 'feat2':(0, 1.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,obj in sample.iterrows():\n",
    "#     print(similarity(pd.DataFrame(d).T, obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = pd.DataFrame([g1, g2, g3, test1, test2])\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat1        (1, 1)\n",
       "feat2    (1.5, 1.5)\n",
       "dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d), type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_included_in_repr(d, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая функция провекри np.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat(times, data):\n",
    "    print(f\"times = {times}\")\n",
    "    sample = np.random.RandomState().choice(data, replace=False, size=10)\n",
    "    print(f\"sample = {sample}\")\n",
    "    sample_sum = np.sum(sample)\n",
    "    print(f\"sample sum = {sample_sum}\")\n",
    "    return sample_sum\n",
    "\n",
    "def run_computing(n_jobs=2):\n",
    "    data = list(range(100))\n",
    "    \n",
    "    compute_func = partial(compute_stat, data=data)\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        results = executor.map(compute_func, list(range(26)))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = run_computing(n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
