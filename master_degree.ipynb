{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions as utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor, Executor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, filename):\n",
    "    print(f'reading file = {os.path.join(path, filename)}')\n",
    "    data = pd.read_csv(os.path.join(path, filename))\n",
    "    data = data.rename(columns={'Unnamed: 0':'Id'})\n",
    "    print(f'data shape = {data.shape}')\n",
    "    types_info = pd.DataFrame(data.dtypes.value_counts(), columns=['columns_count'])\n",
    "    print('types info about df columns: ')\n",
    "    print(types_info)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28272\r\n",
      "drwx------@ 6 adam  staff   192B Dec 23 21:30 \u001b[34m.\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  8 adam  staff   256B Dec 23 21:36 \u001b[34m..\u001b[m\u001b[m/\r\n",
      "-rwxr-xr-x@ 1 adam  staff    15K Dec 11  2019 \u001b[31mData Dictionary.xls\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@ 1 adam  staff   4.8M Dec 11  2019 \u001b[31mcs-test.csv\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@ 1 adam  staff   7.2M Dec 11  2019 \u001b[31mcs-training.csv\u001b[m\u001b[m*\r\n",
      "-rwxr-xr-x@ 1 adam  staff   1.8M Dec 11  2019 \u001b[31msampleEntry.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls -la -h Datasets/GiveMeSomeCredit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file = Datasets/GiveMeSomeCredit/cs-training.csv\n",
      "data shape = (150000, 12)\n",
      "types info about df columns: \n",
      "         columns_count\n",
      "int64                8\n",
      "float64              4\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(path='Datasets/GiveMeSomeCredit/', filename='cs-training.csv')\n",
    "# test_data = read_data(path='Datasets/GiveMeSomeCredit/', filename='cs-test.csv')\n",
    "# descript = pd.read_excel(\"Datasets/GiveMeSomeCredit/Data Dictionary.xls\")\n",
    "# sample_data = pd.read_csv(\"Datasets/GiveMeSomeCredit/sampleEntry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(0, inplace=True)\n",
    "# test_data.fillna(0, inplace=True)\n",
    "\n",
    "#ставим колонку Id как индекс клиента\n",
    "train_data.set_index('Id', inplace=True)\n",
    "# test_data.set_index('Id', inplace=True)\n",
    "\n",
    "#сохраняем метку класса\n",
    "train_label = train_data['SeriousDlqin2yrs'].copy()\n",
    "train_data.drop('SeriousDlqin2yrs', axis=1, inplace=True)\n",
    "#удаляем колонку класса из тестовых данных, так как она не несет никакой информации\n",
    "# test_data.drop('SeriousDlqin2yrs', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['NumberOfDependents'] = train_data.NumberOfDependents.astype('int')\n",
    "train_data['MonthlyIncome'] = train_data.MonthlyIncome.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape#, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = train_data.select_dtypes('float').columns\n",
    "train_data.loc[:, float_cols] = train_data.loc[:, float_cols].round(2)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float_cols = test_data.select_dtypes('float').columns\n",
    "# test_data.loc[:, float_cols] = test_data.loc[:, float_cols].round(2)\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train = transform_to_description(train_data)\n",
    "# transformed_test = transform_to_description(test_data)\n",
    "# transformed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train.shape#, transformed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(transformed_train, train_label, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX, testX, valY, testY = train_test_split(testX, testY, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 10) (30000, 10) (30000, 10)\n",
      "(90000,) (30000,) (30000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, valX.shape, testX.shape)\n",
    "print(trainY.shape, valY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм из работы Алексея(QBCA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "sample_ratio = 0.01\n",
    "num_iters = 100\n",
    "# N_neg = train_label.value_counts().reset_index().iloc[0, 1]\n",
    "# N_pos = train_label.value_counts().reset_index().iloc[1, 1]\n",
    "# N_neg, N_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**не обновляем индекс так как индекс - это id клиента, имеет значимую информацию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83982, 10), (6018, 10))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pos = transformed_train.loc[train_label[train_label == 1].index]\n",
    "# train_neg = transformed_train.loc[train_label[train_label == 0].index]\n",
    "train_pos = trainX.loc[trainY[trainY == 1].index]\n",
    "train_neg = trainX.loc[trainY[trainY == 0].index]\n",
    "\n",
    "train_neg.shape, train_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Берем выборку заемов, для начального тестирования работоспособности**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 10), (2000, 10))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos = train_pos.sample(n=2000, random_state=123, replace=False)\n",
    "train_neg = train_neg.sample(n=2000, random_state=123, replace=False)\n",
    "train_pos.shape, train_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133687</th>\n",
       "      <td>(0.25, 0.25)</td>\n",
       "      <td>(57, 57)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0.26, 0.26)</td>\n",
       "      <td>(7050, 7050)</td>\n",
       "      <td>(24, 24)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RevolvingUtilizationOfUnsecuredLines       age  \\\n",
       "Id                                                      \n",
       "133687                         (0.25, 0.25)  (57, 57)   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse     DebtRatio MonthlyIncome  \\\n",
       "Id                                                                        \n",
       "133687                               (0, 0)  (0.26, 0.26)  (7050, 7050)   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans NumberOfTimes90DaysLate  \\\n",
       "Id                                                               \n",
       "133687                        (24, 24)                  (0, 0)   \n",
       "\n",
       "       NumberRealEstateLoansOrLines NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "Id                                                                         \n",
       "133687                       (0, 0)                               (0, 0)   \n",
       "\n",
       "       NumberOfDependents  \n",
       "Id                         \n",
       "133687             (0, 0)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = valX.sample(1)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining step\n",
    "\n",
    "\n",
    "    для положительного класса нас интересуют объекты отрицательного класса, \n",
    "    а для отрицательного - положительные\n",
    "    Уже после определения объектов из другого класса, попадающие в признаковое представление семпла данных, будет приниматься решение\n",
    "     о включение этого признакого представление в список гипотез представления(областей или интервальных представлений)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно посмотреть:\n",
    "\n",
    "    1. Сравнение количества генерируемых гипотез в зависимости от критерия и области генерации выборки.\n",
    "    (Возможно изобразить всего 4 варианта: старый подход - локальная или случайная выборка, новый подход - \n",
    "    локальная или случайная выборка)\n",
    "    \n",
    "    2. Сравнение генерируемых гипотез для старого и нового критерия в зависимости от ширины локальной области генерации\n",
    "    (Возможно есть какая то оптимальная ширина окна)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do-list:\n",
    "1. **классификации при разном включении признаков из исходного множества**\n",
    "\n",
    "2. **Подумать о том, каким образом генерить гипотезы. То есть выбирать не случайно выборку из множества объектов,\n",
    "    а какую-то локальную область. (Делать будем через расширение области объекта; более того, будем искать \n",
    "    оптимальное значение расширения локальной области) done !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = imp.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hypothesis(iteration: int, obj: pd.Series, object_area: pd.Series, train_data: pd.DataFrame, \n",
    "                        other_data: pd.DataFrame, sample_size: int, hypothesis_criterion: str,\n",
    "                        sample_type:str, verbose: bool, alpha: float):\n",
    "        \n",
    "        print(f'iteration: {iteration}')\n",
    "        \n",
    "        if sample_type == 'local' and object_area is None:\n",
    "            print(f'Cannot generate sample from local area. Got None as local object area param!')\n",
    "            return None\n",
    "    \n",
    "        if sample_type == 'random' and object_area is not None:\n",
    "            print(f'got misleading params values. Got sample_type = None and local object area is not None')\n",
    "            return None\n",
    "\n",
    "        #generating random sample using sample strategy = {sample_type}\n",
    "        sample = utils.generate_random_sample(train_data=train_data, sample_size=sample_size, d=object_area) \n",
    "        sample.append(obj)\n",
    "        \n",
    "        d = utils.get_similarity_sample_repr(sample)\n",
    "        if verbose:\n",
    "            print('got feature represantation for sample')\n",
    "        \n",
    "        d_other_objects = is_included_in_repr(d, train_data=other_data)\n",
    "        #print(f'got {len(d_other_objects)} d_other_objects')\n",
    "        #print(f'thresh for hypothesis = {int(other_data_size * alpha)}')\n",
    "        \n",
    "#         if verbose:\n",
    "#             print('got objects that is included in sample represantation')\n",
    "        #!!!!!!!\n",
    "        # Тут момент такой, что вроде если d_other_objects тоже подходит, так как в этой области только объекты одного класса\n",
    "        # а объектов другого просто нет\n",
    "        if d_other_objects is None:\n",
    "            print('!'*20)\n",
    "            print('did not find any hypothesis on this iteration')\n",
    "            return d # эта гипотеза подходит, никого нет из другого класса, можно больше ничего не проверять\n",
    "        \n",
    "        \n",
    "        result_hypothesis = utils.check_criterion(d=d, train_data=train_data, \n",
    "                                                  hypothesis_criterion=hypothesis_criterion, \n",
    "                                                  d_other_objects=d_other_objects,\n",
    "                                                  other_data=other_data, alpha=alpha\n",
    "                                                 )\n",
    "\n",
    "        return result_hypothesis\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "def mining_step(test_obj: pd.Series,train_pos: pd.DataFrame, train_neg: pd.DataFrame, num_iters: int, \n",
    "                sample_ratio: float, alpha: float, hypothesis_criterion: str, sample_type: str,\n",
    "                mining_type: str = 'pos', verbose : bool = False, n_jobs : int = 4):\n",
    "    \"\"\"\n",
    "    hypothesis_criterion: 'contr_class', если используем базовый критерий, \n",
    "                                когда смотрится пересечение с противоположным классом(старый критерий отбора гипотез)\n",
    "                           'both_classes', когда интересует пересечение по обоим классам(новый критерий отбора гипотез)\n",
    "                           \n",
    "    sample_type: 'random', если берем произвольную выборку интервальных представлений\n",
    "                 'local', если берем произвольную выборку из локальной области\n",
    "    \n",
    "    returns list of hypothesises\n",
    "    \"\"\"\n",
    "    \n",
    "    if sample_type == 'local':\n",
    "        #sampling\n",
    "        print(f'start searching optimal local area')\n",
    "        object_area = utils.find_opt_local_area(obj=test_obj,\n",
    "                                                train_data=train_data,\n",
    "                                                frac=0.15,\n",
    "                                                num_iters=30\n",
    "                                               )\n",
    "    else:\n",
    "        print(f'using random sample from train data')\n",
    "        object_area = None\n",
    "    \n",
    "    train_data = train_pos if mining_type == 'pos' else train_neg\n",
    "    other_data = train_neg if mining_type == 'pos' else train_pos\n",
    "    sample_size = int(train_data.shape[0] * sample_ratio)\n",
    "    print('start generating hypothesises')\n",
    "    \n",
    "    mining = partial(generate_hypothesis, \n",
    "                     obj=test_obj, \n",
    "                     object_area=object_area,\n",
    "                     train_data=train_data, \n",
    "                     other_data=other_data, \n",
    "                     sample_size=sample_size, \n",
    "                     hypothesis_criterion=hypothesis_criterion,\n",
    "                     sample_type=sample_type,\n",
    "                     verbose=verbose,\n",
    "                     alpha=alpha\n",
    "                    )\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        hypothesises = executor.map(mining, range(num_iters))\n",
    "\n",
    "    hypothesises = [res for res in hypothesises if res is not None]\n",
    "    print(f'All hypothesises are generated!')\n",
    "    return hypothesises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     area = find_opt_local_area(obj=obj, train_data=train_pos, num_iters=100)\n",
    "#     if area is not None:\n",
    "#         print('we found area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_local_sample(d=area, train_data=train_pos, sample_size=int(sample_ratio * train_pos.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_neg_objs = is_included_in_repr(d=area, train_data=train_neg)\n",
    "# local_objs = is_included_in_repr(d=area, train_data=train_pos)\n",
    "# len(local_objs), train_pos.shape, len(local_neg_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     sample = generate_local_sample(obj, train_data=train_pos, sample_size=3, num_iters=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, obj in test_sample.iterrows():\n",
    "#     print(type(obj))\n",
    "# #     generate_local_sample(obj=obj, train_data=train_pos, sample_size=3)\n",
    "#     generated = generate_local_area(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_local_obj = transformed_train.sample(1)\n",
    "# test_local_obj\n",
    "\n",
    "# generated_obj = generate_local_area(test_local_obj)\n",
    "# generated_obj\n",
    "\n",
    "# generate_local_area(generated_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_hyps = []\n",
    "neg_hyps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация гипотез для полож класса занимает 10 мин (с 4 процессами) c 3000 iterations**\n",
    "**c 1000 iterations - 2 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for i, obj in test_sample.iterrows():\n",
    "#     print(type(obj))\n",
    "#     print(f'start mining from pos objects')\n",
    "#     pos_hyps = mining_step(test_obj=obj, train_pos=train_pos, train_neg=train_neg, \n",
    "#                            num_iters=num_iters,sample_ratio=sample_ratio, alpha = alpha,\n",
    "#                            hypothesis_criterion='contr_class',\n",
    "#                            sample_type='local',\n",
    "#                            mining_type='pos',\n",
    "#                            verbose=False, n_jobs=4\n",
    "#                           )\n",
    "    \n",
    "# #     print(f'start mining from neg objects')\n",
    "# #     neg_hyps = mining_step(test_obj=obj, train_pos=train_pos, train_neg=train_neg,\n",
    "# #                            num_iters=num_iters, sample_ratio=sample_ratio, alpha = alpha, \n",
    "# #                            hypothesis_criterion='contr_class',mining_type='neg', \n",
    "# #                            sample_type='',\n",
    "# #                            verbose=True, n_jobs=4\n",
    "# #                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.Series({'feat1':(1,1), 'feat2':(0, 1.4), 'feat3':(3, 4)})\n",
    "# b = pd.Series({'feat1':(1,2), 'feat2':(1, 1.4), 'feat3':(7, 7)})\n",
    "# c = pd.Series({'feat1':(1,1), 'feat2':(0.8, 1.6), 'feat3':(3, 4)})\n",
    "# d = pd.Series({'feat1':(2,3), 'feat2':(0, 1.4), 'feat3':(4, 6)})\n",
    "\n",
    "\n",
    "# print(a.equals(b))\n",
    "# print(a == b)\n",
    "\n",
    "# test1 = pd.Series({'feat1':(1,3), 'feat2':(1, 3.4), 'feat3':(1, 1.9)})\n",
    "# test2 = pd.Series({'feat1':(2,2.2), 'feat2':(2, 2.4), 'feat3':(3, 3.9)})\n",
    "# test3 = pd.Series({'feat1':(3,3), 'feat2':(4, 4.4), 'feat3':(4, 4.9)})\n",
    "\n",
    "g1 = pd.Series({'feat1':(1,1), 'feat2':(1.5, 1.5)})\n",
    "g2 = pd.DataFrame({'feat1':(-1,-1), 'feat2':(0, 0)})\n",
    "g3 = pd.Series({'feat1':(0.5,0.5), 'feat2':(1, 1)})\n",
    "\n",
    "test1 = pd.Series({'feat1':(0.1, 1), 'feat2':(-0.5, 0)})\n",
    "test2 = pd.DataFrame({'feat1':(-0.1, 1), 'feat2':(0.5, 0.8)})\n",
    "tst = pd.Series({'feat1':(-1, 1), 'feat2':(0, 1.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,obj in sample.iterrows():\n",
    "#     print(similarity(pd.DataFrame(d).T, obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = pd.DataFrame([g1, g2, g3, test1, test2])\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat1        (1, 1)\n",
       "feat2    (1.5, 1.5)\n",
       "dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d), type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_included_in_repr(d, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая функция провекри np.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat(times, data):\n",
    "    print(f\"times = {times}\")\n",
    "    sample = np.random.RandomState().choice(data, replace=False, size=10)\n",
    "    print(f\"sample = {sample}\")\n",
    "    sample_sum = np.sum(sample)\n",
    "    print(f\"sample sum = {sample_sum}\")\n",
    "    return sample_sum\n",
    "\n",
    "def run_computing(n_jobs=2):\n",
    "    data = list(range(100))\n",
    "    \n",
    "    compute_func = partial(compute_stat, data=data)\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        results = executor.map(compute_func, list(range(26)))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = run_computing(n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
